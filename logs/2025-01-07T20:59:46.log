{"n_layers": 1, "device": "cuda", "batch_size": 2048, "embedding_dim": 512, "learning_rate": 0.0005, "dataset": "dbbook", "epochs": 150, "top_k": 20, "multimodal": false, "datasets": {"dbbook": ["images", "text"], "ml1m": ["audio", "images", "text", "video"]}}
Epoch	Loss	Recall	Precision	NDCG
1	0.6900	0.0174	0.0060	0.0144
2	0.6865	0.0561	0.0202	0.0436
3	0.6801	0.0800	0.0281	0.0574
4	0.6675	0.0826	0.0288	0.0578
5	0.6449	0.0802	0.0281	0.0557
6	0.6097	0.0790	0.0275	0.0543
7	0.5633	0.0757	0.0269	0.0522
8	0.5113	0.0743	0.0265	0.0514
9	0.4600	0.0735	0.0263	0.0508
10	0.4127	0.0729	0.0263	0.0509
11	0.3736	0.0741	0.0266	0.0516
12	0.3403	0.0748	0.0269	0.0522
13	0.3103	0.0756	0.0272	0.0531
14	0.2863	0.0766	0.0275	0.0538
15	0.2635	0.0777	0.0278	0.0546
16	0.2444	0.0785	0.0281	0.0551
17	0.2298	0.0794	0.0283	0.0558
18	0.2174	0.0806	0.0287	0.0567
19	0.2037	0.0816	0.0291	0.0578
20	0.1898	0.0822	0.0292	0.0584
21	0.1771	0.0833	0.0295	0.0592
22	0.1658	0.0843	0.0298	0.0600
23	0.1583	0.0858	0.0302	0.0611
24	0.1483	0.0877	0.0307	0.0626
25	0.1418	0.0892	0.0309	0.0633
26	0.1330	0.0905	0.0313	0.0641
27	0.1274	0.0922	0.0318	0.0651
28	0.1186	0.0930	0.0321	0.0656
29	0.1144	0.0941	0.0324	0.0663
30	0.1097	0.0952	0.0326	0.0671
31	0.1039	0.0961	0.0329	0.0678
32	0.0990	0.0967	0.0331	0.0683
33	0.0931	0.0977	0.0334	0.0690
34	0.0898	0.0984	0.0337	0.0698
35	0.0870	0.0989	0.0340	0.0708
36	0.0833	0.0997	0.0341	0.0717
37	0.0789	0.1007	0.0344	0.0725
38	0.0777	0.1010	0.0346	0.0730
39	0.0723	0.1015	0.0347	0.0733
40	0.0693	0.1022	0.0350	0.0738
41	0.0681	0.1030	0.0352	0.0743
42	0.0637	0.1030	0.0352	0.0748
43	0.0621	0.1038	0.0354	0.0754
44	0.0594	0.1049	0.0356	0.0762
45	0.0601	0.1052	0.0357	0.0767
46	0.0553	0.1057	0.0359	0.0772
47	0.0552	0.1070	0.0362	0.0779
48	0.0529	0.1073	0.0363	0.0782
49	0.0507	0.1082	0.0365	0.0788
50	0.0502	0.1084	0.0366	0.0791
51	0.0481	0.1087	0.0367	0.0797
52	0.0462	0.1092	0.0368	0.0800
53	0.0453	0.1096	0.0369	0.0804
54	0.0446	0.1101	0.0372	0.0810
55	0.0415	0.1099	0.0371	0.0811
56	0.0409	0.1100	0.0371	0.0812
57	0.0390	0.1103	0.0372	0.0816
58	0.0399	0.1110	0.0374	0.0822
59	0.0367	0.1113	0.0375	0.0827
60	0.0375	0.1114	0.0375	0.0829
61	0.0340	0.1118	0.0376	0.0833
62	0.0349	0.1121	0.0377	0.0835
63	0.0341	0.1123	0.0377	0.0837
64	0.0329	0.1122	0.0377	0.0838
65	0.0328	0.1124	0.0378	0.0840
66	0.0327	0.1130	0.0379	0.0845
67	0.0306	0.1135	0.0381	0.0849
68	0.0305	0.1137	0.0382	0.0849
69	0.0298	0.1141	0.0383	0.0852
70	0.0279	0.1141	0.0383	0.0854
71	0.0292	0.1144	0.0384	0.0858
72	0.0268	0.1148	0.0385	0.0862
73	0.0280	0.1147	0.0385	0.0861
74	0.0265	0.1153	0.0387	0.0863
75	0.0260	0.1154	0.0387	0.0866
76	0.0251	0.1154	0.0387	0.0867
77	0.0248	0.1154	0.0387	0.0868
78	0.0242	0.1156	0.0387	0.0869
79	0.0234	0.1160	0.0388	0.0870
80	0.0232	0.1157	0.0387	0.0870
81	0.0230	0.1162	0.0388	0.0872
82	0.0226	0.1162	0.0389	0.0872
83	0.0220	0.1167	0.0390	0.0875
84	0.0219	0.1166	0.0390	0.0877
85	0.0220	0.1169	0.0390	0.0879
86	0.0219	0.1166	0.0389	0.0878
87	0.0203	0.1172	0.0391	0.0882
88	0.0213	0.1179	0.0392	0.0885
89	0.0211	0.1177	0.0392	0.0887
90	0.0196	0.1177	0.0393	0.0888
91	0.0187	0.1174	0.0392	0.0888
92	0.0186	0.1177	0.0393	0.0889
93	0.0189	0.1175	0.0393	0.0889
94	0.0184	0.1177	0.0394	0.0890
95	0.0185	0.1176	0.0393	0.0890
96	0.0181	0.1178	0.0393	0.0892
97	0.0183	0.1182	0.0394	0.0894
98	0.0178	0.1189	0.0394	0.0896
99	0.0171	0.1187	0.0393	0.0896
100	0.0170	0.1189	0.0394	0.0897
101	0.0170	0.1185	0.0393	0.0895
102	0.0162	0.1183	0.0392	0.0894
103	0.0160	0.1185	0.0393	0.0896
104	0.0163	0.1183	0.0392	0.0896
105	0.0159	0.1182	0.0392	0.0897
106	0.0158	0.1184	0.0392	0.0897
107	0.0160	0.1185	0.0391	0.0897
108	0.0149	0.1188	0.0392	0.0898
109	0.0151	0.1189	0.0392	0.0899
110	0.0152	0.1194	0.0393	0.0901
111	0.0143	0.1192	0.0392	0.0901
112	0.0151	0.1199	0.0393	0.0905
113	0.0145	0.1197	0.0392	0.0905
114	0.0147	0.1196	0.0391	0.0902
115	0.0145	0.1192	0.0391	0.0901
116	0.0139	0.1191	0.0391	0.0901
117	0.0137	0.1189	0.0390	0.0903
118	0.0139	0.1192	0.0391	0.0902
119	0.0136	0.1196	0.0391	0.0904
120	0.0128	0.1195	0.0391	0.0904
121	0.0134	0.1198	0.0391	0.0905
122	0.0136	0.1195	0.0390	0.0907
123	0.0132	0.1201	0.0391	0.0910
124	0.0121	0.1200	0.0391	0.0909
125	0.0125	0.1199	0.0391	0.0907
126	0.0125	0.1200	0.0391	0.0909
127	0.0128	0.1198	0.0391	0.0908
128	0.0126	0.1198	0.0391	0.0908
129	0.0121	0.1199	0.0391	0.0910
130	0.0122	0.1201	0.0391	0.0910
131	0.0121	0.1206	0.0392	0.0913
132	0.0120	0.1204	0.0391	0.0912
133	0.0125	0.1206	0.0391	0.0915
134	0.0116	0.1200	0.0390	0.0913
135	0.0116	0.1207	0.0391	0.0913
136	0.0110	0.1206	0.0391	0.0913
137	0.0105	0.1205	0.0390	0.0912
138	0.0114	0.1206	0.0391	0.0912
139	0.0107	0.1205	0.0390	0.0911
140	0.0115	0.1202	0.0390	0.0911
141	0.0107	0.1203	0.0390	0.0910
142	0.0110	0.1204	0.0390	0.0911
143	0.0108	0.1206	0.0390	0.0913
144	0.0108	0.1208	0.0390	0.0914
145	0.0104	0.1204	0.0389	0.0911
146	0.0102	0.1207	0.0389	0.0912
147	0.0102	0.1207	0.0389	0.0912
148	0.0101	0.1206	0.0389	0.0912
149	0.0104	0.1207	0.0389	0.0911
150	0.0109	0.1211	0.0390	0.0915
